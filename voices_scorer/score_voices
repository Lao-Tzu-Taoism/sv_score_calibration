#!/usr/bin/env python
"""
Scoring script for VOiCES from a Distance Challenge

Author: Mitchell McLaren
Email: mitchell.mclaren@sri.com
Date: January 7. 2016 (v2 SITW scoring script)
Date: January 23, 2019 (revised for VOiCES)
"""
import os, sys, time

import argparse
from voices_tools import *

if(__name__=="__main__"):
    desc = "Evaluate performance of a scorefile against a key, or check a score submission against a trial list (with -c option)."
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("-c", "--check", action="store_true", help="Check submission against a trial list",default=False)
    parser.add_argument("--label-column", metavar='label_column', type=int, choices=[1,3], default=3, help="label index in trails and score file")
    parser.add_argument("--p-target", type=float, default=0.01, help="p-target for minDCF, actDCF metric")
    parser.add_argument('score_file', help="One or more score files. Each line is a triple <enrolled_speaker> <test_speaker> <LLR_score>")
    parser.add_argument('key_file', help="Speaker recognition key file. Each line is a triple <enrolled_speaker> <test_speaker> target|nontarget")

    args = parser.parse_args()
    scorefile, keyfile = args.score_file, args.key_file

    # Load the scores from ascii file
    scores = Scores.load(scorefile, label_column=args.label_column)

    # Load the key file
    key = Key.load(keyfile, notruth=args.check, label_column=args.label_column)
    
    # Align the score and key in terms of model and test id ordering
    # An exception will be raised if any scores are missing according to the key
    scores = scores.align(key)

    if args.check:
        print("Submission check PASSED")
    else:
        # Calculate and print performance metrics
        print_performance(scores,key,p_tar=args.p_target)
